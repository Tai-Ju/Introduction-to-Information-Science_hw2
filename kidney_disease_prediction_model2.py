#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è…è‡Ÿç–¾ç—…é æ¸¬æ¨¡å‹ - å®Œæ•´åˆ†æä»£ç¢¼
åŒ…å«è³‡æ–™é è™•ç†ã€æ¨¡å‹è¨“ç·´ã€æ€§èƒ½è©•ä¼°ã€è¦–è¦ºåŒ–åˆ†æ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, 
                           confusion_matrix, roc_auc_score, roc_curve, 
                           precision_recall_curve, classification_report)
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class KidneyDiseasePredictor:
    """è…è‡Ÿç–¾ç—…é æ¸¬åˆ†æå™¨"""
    
    def __init__(self, data_path):
        """åˆå§‹åŒ–é æ¸¬å™¨"""
        self.data_path = data_path
        self.data = None
        self.X = None
        self.y = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.models = {}
        self.results = {}
        
        # å®šç¾©éœ€è¦ç§»é™¤çš„è³‡æ–™æ´©æ¼ç‰¹å¾µ
        self.leakage_features = ['Anemia: yes', 'Pedal Edema: yes', 'Appetite: poor']
        
        print("ğŸ¥ è…è‡Ÿç–¾ç—…é æ¸¬æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š è³‡æ–™è·¯å¾‘: {data_path}")
        print(f"ğŸš¨ å°‡ç§»é™¤è³‡æ–™æ´©æ¼ç‰¹å¾µ: {self.leakage_features}")
    
    def load_and_explore_data(self):
        """è¼‰å…¥ä¸¦æ¢ç´¢è³‡æ–™"""
        print("\n" + "="*60)
        print("ğŸ“Š æ­¥é©Ÿ1: è¼‰å…¥ä¸¦æ¢ç´¢è³‡æ–™")
        print("="*60)
        
        # è¼‰å…¥è³‡æ–™
        self.data = pd.read_csv(self.data_path)
        print(f"âœ… è³‡æ–™è¼‰å…¥æˆåŠŸ")
        print(f"   è³‡æ–™å½¢ç‹€: {self.data.shape}")
        print(f"   ç‰¹å¾µæ•¸é‡: {self.data.shape[1] - 1}")
        print(f"   æ¨£æœ¬æ•¸é‡: {self.data.shape[0]}")
        
        # é¡¯ç¤ºåŸºæœ¬è³‡è¨Š
        print(f"\nğŸ“‹ è³‡æ–™åŸºæœ¬è³‡è¨Š:")
        print(f"   æ¬„ä½åç¨±: {list(self.data.columns)}")
        
        # æª¢æŸ¥ç›®æ¨™è®Šæ•¸
        target_col = self.data.columns[-1]
        print(f"\nğŸ¯ ç›®æ¨™è®Šæ•¸: {target_col}")
        print(f"   é¡åˆ¥åˆ†å¸ƒ:")
        target_counts = self.data[target_col].value_counts()
        for class_name, count in target_counts.items():
            percentage = (count / len(self.data)) * 100
            print(f"   - {class_name}: {count} ({percentage:.1f}%)")
        
        # æª¢æŸ¥éºå¤±å€¼
        print(f"\nğŸ” éºå¤±å€¼æª¢æŸ¥:")
        missing_values = self.data.isnull().sum()
        if missing_values.sum() == 0:
            print("   âœ… ç„¡éºå¤±å€¼")
        else:
            print("   âš ï¸ ç™¼ç¾éºå¤±å€¼:")
            for col, missing_count in missing_values[missing_values > 0].items():
                print(f"   - {col}: {missing_count}")
        
        return self.data
    
    def preprocess_data(self):
        """é è™•ç†è³‡æ–™"""
        print("\n" + "="*60)
        print("ğŸ”§ æ­¥é©Ÿ2: è³‡æ–™é è™•ç†")
        print("="*60)
        
        # ç§»é™¤è³‡æ–™æ´©æ¼ç‰¹å¾µ
        print(f"ğŸš¨ ç§»é™¤è³‡æ–™æ´©æ¼ç‰¹å¾µ:")
        for feature in self.leakage_features:
            if feature in self.data.columns:
                print(f"   - ç§»é™¤: {feature}")
                self.data = self.data.drop(columns=[feature])
            else:
                print(f"   - æœªæ‰¾åˆ°: {feature}")
        
        print(f"âœ… ç§»é™¤å¾Œè³‡æ–™å½¢ç‹€: {self.data.shape}")
        
        # åˆ†é›¢ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸
        self.X = self.data.iloc[:, :-1]  # æ‰€æœ‰æ¬„ä½é™¤äº†æœ€å¾Œä¸€æ¬„
        self.y = self.data.iloc[:, -1]   # æœ€å¾Œä¸€æ¬„æ˜¯ç›®æ¨™è®Šæ•¸
        
        print(f"\nğŸ“Š ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸åˆ†é›¢:")
        print(f"   ç‰¹å¾µçŸ©é™£ X: {self.X.shape}")
        print(f"   ç›®æ¨™è®Šæ•¸ y: {self.y.shape}")
        
        # è™•ç†åˆ†é¡è®Šæ•¸
        print(f"\nğŸ”¤ è™•ç†åˆ†é¡è®Šæ•¸:")
        categorical_columns = self.X.select_dtypes(include=['object']).columns
        if len(categorical_columns) > 0:
            print(f"   ç™¼ç¾åˆ†é¡è®Šæ•¸: {list(categorical_columns)}")
            for col in categorical_columns:
                le = LabelEncoder()
                original_values = self.X[col].unique()
                self.X[col] = le.fit_transform(self.X[col].astype(str))
                print(f"   - {col}: {original_values} â†’ {self.X[col].unique()}")
        else:
            print("   âœ… ç„¡åˆ†é¡è®Šæ•¸éœ€è¦è™•ç†")
        
        # è™•ç†ç›®æ¨™è®Šæ•¸
        print(f"\nğŸ¯ è™•ç†ç›®æ¨™è®Šæ•¸:")
        if self.y.dtype == 'object':
            le_target = LabelEncoder()
            original_classes = self.y.unique()
            self.y = le_target.fit_transform(self.y)
            print(f"   ç›®æ¨™è®Šæ•¸ç·¨ç¢¼: {original_classes} â†’ {np.unique(self.y)}")
            # å„²å­˜ç·¨ç¢¼å™¨ä»¥ä¾›å¾ŒçºŒä½¿ç”¨
            self.target_encoder = le_target
        else:
            print("   âœ… ç›®æ¨™è®Šæ•¸å·²ç‚ºæ•¸å€¼å‹")
        
        # è™•ç†éºå¤±å€¼
        print(f"\nğŸ”§ è™•ç†éºå¤±å€¼:")
        if self.X.isnull().sum().sum() > 0:
            imputer = SimpleImputer(strategy='median')
            self.X = pd.DataFrame(
                imputer.fit_transform(self.X),
                columns=self.X.columns,
                index=self.X.index
            )
            print(f"   âœ… ä½¿ç”¨ä¸­ä½æ•¸å¡«è£œéºå¤±å€¼")
        else:
            print("   âœ… ç„¡éºå¤±å€¼éœ€è¦è™•ç†")
        
        print(f"\nâœ… è³‡æ–™é è™•ç†å®Œæˆ")
        print(f"   æœ€çµ‚ç‰¹å¾µçŸ©é™£: {self.X.shape}")
        print(f"   ç‰¹å¾µåç¨±: {list(self.X.columns)}")
        
        return self.X, self.y
    
    def split_data(self, test_size=0.2, random_state=42):
        """åˆ†å‰²è¨“ç·´é›†å’Œæ¸¬è©¦é›†"""
        print("\n" + "="*60)
        print("âœ‚ï¸ æ­¥é©Ÿ3: åˆ†å‰²è¨“ç·´é›†å’Œæ¸¬è©¦é›†")
        print("="*60)
        
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            self.X, self.y, test_size=test_size, random_state=random_state, 
            stratify=self.y  # ä¿æŒé¡åˆ¥æ¯”ä¾‹
        )
        
        print(f"ğŸ“Š è³‡æ–™åˆ†å‰²çµæœ:")
        print(f"   è¨“ç·´é›†: {self.X_train.shape}")
        print(f"   æ¸¬è©¦é›†: {self.X_test.shape}")
        print(f"   æ¸¬è©¦é›†æ¯”ä¾‹: {test_size*100:.0f}%")
        
        # æª¢æŸ¥é¡åˆ¥åˆ†å¸ƒ
        train_dist = pd.Series(self.y_train).value_counts().sort_index()
        test_dist = pd.Series(self.y_test).value_counts().sort_index()
        
        print(f"\nğŸ“ˆ é¡åˆ¥åˆ†å¸ƒ:")
        print(f"   è¨“ç·´é›†: {dict(train_dist)}")
        print(f"   æ¸¬è©¦é›†: {dict(test_dist)}")
        
        return self.X_train, self.X_test, self.y_train, self.y_test
    
    def train_decision_tree(self, max_depth=5, min_samples_split=10, min_samples_leaf=5):
        """è¨“ç·´æ±ºç­–æ¨¹æ¨¡å‹"""
        print("\n" + "="*40)
        print("ğŸŒ³ è¨“ç·´æ±ºç­–æ¨¹æ¨¡å‹")
        print("="*40)
        
        # å‰µå»ºå’Œè¨“ç·´æ±ºç­–æ¨¹
        dt_model = DecisionTreeClassifier(
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            random_state=42
        )
        
        dt_model.fit(self.X_train, self.y_train)
        
        # é æ¸¬
        y_train_pred = dt_model.predict(self.X_train)
        y_test_pred = dt_model.predict(self.X_test)
        y_test_proba = dt_model.predict_proba(self.X_test)[:, 1]
        
        # äº¤å‰é©—è­‰
        cv_scores = cross_val_score(
            dt_model, self.X, self.y, 
            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
            scoring='accuracy'
        )
        
        # è¨ˆç®—æ€§èƒ½æŒ‡æ¨™
        dt_results = {
            'model': dt_model,
            'train_accuracy': accuracy_score(self.y_train, y_train_pred),
            'test_accuracy': accuracy_score(self.y_test, y_test_pred),
            'cv_accuracy': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'precision': precision_score(self.y_test, y_test_pred),
            'recall': recall_score(self.y_test, y_test_pred),
            'f1': f1_score(self.y_test, y_test_pred),
            'roc_auc': roc_auc_score(self.y_test, y_test_proba),
            'y_test_pred': y_test_pred,
            'y_test_proba': y_test_proba,
            'feature_importance': pd.DataFrame({
                'feature': self.X.columns,
                'importance': dt_model.feature_importances_
            }).sort_values('importance', ascending=False)
        }
        
        self.models['decision_tree'] = dt_model
        self.results['decision_tree'] = dt_results
        
        print(f"âœ… æ±ºç­–æ¨¹è¨“ç·´å®Œæˆ")
        print(f"   è¨“ç·´é›†æº–ç¢ºç‡: {dt_results['train_accuracy']:.4f}")
        print(f"   æ¸¬è©¦é›†æº–ç¢ºç‡: {dt_results['test_accuracy']:.4f}")
        print(f"   äº¤å‰é©—è­‰æº–ç¢ºç‡: {dt_results['cv_accuracy']:.4f} Â± {dt_results['cv_std']:.4f}")
        print(f"   ç²¾ç¢ºç‡: {dt_results['precision']:.4f}")
        print(f"   å¬å›ç‡: {dt_results['recall']:.4f}")
        print(f"   F1åˆ†æ•¸: {dt_results['f1']:.4f}")
        print(f"   ROC AUC: {dt_results['roc_auc']:.4f}")
        
        return dt_model, dt_results
    
    def train_logistic_regression(self):
        """è¨“ç·´é‚è¼¯å›æ­¸æ¨¡å‹"""
        print("\n" + "="*40)
        print("ğŸ“Š è¨“ç·´é‚è¼¯å›æ­¸æ¨¡å‹")
        print("="*40)
        
        # æ¨™æº–åŒ–ç‰¹å¾µ
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(self.X_train)
        X_test_scaled = scaler.transform(self.X_test)
        X_scaled = scaler.fit_transform(self.X)
        
        # å‰µå»ºå’Œè¨“ç·´é‚è¼¯å›æ­¸
        lr_model = LogisticRegression(
            class_weight='balanced',
            max_iter=1000,
            random_state=42
        )
        
        lr_model.fit(X_train_scaled, self.y_train)
        
        # é æ¸¬
        y_train_pred = lr_model.predict(X_train_scaled)
        y_test_pred = lr_model.predict(X_test_scaled)
        y_test_proba = lr_model.predict_proba(X_test_scaled)[:, 1]
        
        # äº¤å‰é©—è­‰
        cv_scores = cross_val_score(
            lr_model, X_scaled, self.y,
            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
            scoring='accuracy'
        )
        
        # è¨ˆç®—æ€§èƒ½æŒ‡æ¨™
        lr_results = {
            'model': lr_model,
            'scaler': scaler,
            'train_accuracy': accuracy_score(self.y_train, y_train_pred),
            'test_accuracy': accuracy_score(self.y_test, y_test_pred),
            'cv_accuracy': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'precision': precision_score(self.y_test, y_test_pred),
            'recall': recall_score(self.y_test, y_test_pred),
            'f1': f1_score(self.y_test, y_test_pred),
            'roc_auc': roc_auc_score(self.y_test, y_test_proba),
            'y_test_pred': y_test_pred,
            'y_test_proba': y_test_proba,
            'feature_importance': pd.DataFrame({
                'feature': self.X.columns,
                'importance': np.abs(lr_model.coef_[0])
            }).sort_values('importance', ascending=False)
        }
        
        self.models['logistic_regression'] = lr_model
        self.results['logistic_regression'] = lr_results
        
        print(f"âœ… é‚è¼¯å›æ­¸è¨“ç·´å®Œæˆ")
        print(f"   è¨“ç·´é›†æº–ç¢ºç‡: {lr_results['train_accuracy']:.4f}")
        print(f"   æ¸¬è©¦é›†æº–ç¢ºç‡: {lr_results['test_accuracy']:.4f}")
        print(f"   äº¤å‰é©—è­‰æº–ç¢ºç‡: {lr_results['cv_accuracy']:.4f} Â± {lr_results['cv_std']:.4f}")
        print(f"   ç²¾ç¢ºç‡: {lr_results['precision']:.4f}")
        print(f"   å¬å›ç‡: {lr_results['recall']:.4f}")
        print(f"   F1åˆ†æ•¸: {lr_results['f1']:.4f}")
        print(f"   ROC AUC: {lr_results['roc_auc']:.4f}")
        
        return lr_model, lr_results
    
    def compare_models(self):
        """æ¯”è¼ƒæ¨¡å‹æ€§èƒ½"""
        print("\n" + "="*60)
        print("ğŸ” æ­¥é©Ÿ4: æ¨¡å‹æ€§èƒ½æ¯”è¼ƒ")
        print("="*60)
        
        # æº–å‚™æ¯”è¼ƒè³‡æ–™
        comparison_data = []
        for model_name, results in self.results.items():
            comparison_data.append({
                'Model': model_name.replace('_', ' ').title(),
                'CV Accuracy': f"{results['cv_accuracy']:.4f} Â± {results['cv_std']:.4f}",
                'Test Accuracy': f"{results['test_accuracy']:.4f}",
                'Precision': f"{results['precision']:.4f}",
                'Recall': f"{results['recall']:.4f}",
                'F1 Score': f"{results['f1']:.4f}",
                'ROC AUC': f"{results['roc_auc']:.4f}"
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        print("ğŸ“Š æ¨¡å‹æ€§èƒ½æ¯”è¼ƒè¡¨:")
        print(comparison_df.to_string(index=False))
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_accuracy = max(results['test_accuracy'] for results in self.results.values())
        best_model = [name for name, results in self.results.items() 
                     if results['test_accuracy'] == best_accuracy][0]
        
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model.replace('_', ' ').title()}")
        print(f"   æ¸¬è©¦é›†æº–ç¢ºç‡: {best_accuracy:.4f}")
        
        return comparison_df
    
    def create_visualizations(self, save_path='/mnt/user-data/outputs/'):
        """å‰µå»ºæ‰€æœ‰è¦–è¦ºåŒ–åœ–è¡¨"""
        print("\n" + "="*60)
        print("ğŸ“ˆ æ­¥é©Ÿ5: å‰µå»ºè¦–è¦ºåŒ–åˆ†æ")
        print("="*60)
        
        # è¨­å®šåœ–è¡¨æ¨£å¼
        plt.style.use('default')
        
        # 1. ç›®æ¨™è®Šæ•¸åˆ†å¸ƒåœ–
        print("ğŸ“Š ç”Ÿæˆåœ–è¡¨ 1/9: ç›®æ¨™è®Šæ•¸åˆ†å¸ƒ")
        plt.figure(figsize=(8, 6))
        target_counts = pd.Series(self.y).value_counts().sort_index()
        bars = plt.bar(range(len(target_counts)), target_counts.values, 
                      color=['skyblue', 'lightcoral'])
        plt.xlabel('Class')
        plt.ylabel('Count')
        plt.title('Target Variable Distribution\n(Kidney Disease Classification)')
        plt.xticks(range(len(target_counts)), 
                  ['No Disease', 'Disease'] if len(target_counts) == 2 else target_counts.index)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i, (bar, count) in enumerate(zip(bars, target_counts.values)):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                    f'{count}\n({count/sum(target_counts.values)*100:.1f}%)',
                    ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig(f'{save_path}01_target_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. ç›¸é—œæ€§çŸ©é™£
        print("ğŸ“Š ç”Ÿæˆåœ–è¡¨ 2/9: ç‰¹å¾µç›¸é—œæ€§çŸ©é™£")
        plt.figure(figsize=(12, 10))
        correlation_matrix = self.X.corr()
        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
                   fmt='.2f', square=True, cbar_kws={'shrink': 0.8})
        plt.title('Feature Correlation Matrix')
        plt.tight_layout()
        plt.savefig(f'{save_path}02_correlation_matrix.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. é‡è¦ç‰¹å¾µèˆ‡ç›®æ¨™çš„ç›¸é—œæ€§
        print("ğŸ“Š ç”Ÿæˆåœ–è¡¨ 3/9: é‡è¦ç‰¹å¾µç›¸é—œæ€§")
        plt.figure(figsize=(10, 8))
        feature_target_corr = self.X.corrwith(pd.Series(self.y)).abs().sort_values(ascending=False)
        top_features = feature_target_corr.head(10)
        
        bars = plt.barh(range(len(top_features)), top_features.values)
        plt.yticks(range(len(top_features)), top_features.index)
        plt.xlabel('Absolute Correlation with Target')
        plt.title('Top 10 Features with Highest Correlation to Chronic Kidney Disease')
        plt.gca().invert_yaxis()
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i, (bar, value) in enumerate(zip(bars, top_features.values)):
            plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, 
                    f'{value:.3f}', va='center')
        
        plt.tight_layout()
        plt.savefig(f'{save_path}03_feature_correlation.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 4. æ··æ·†çŸ©é™£æ¯”è¼ƒ
        print("ğŸ“Š ç”Ÿæˆåœ–è¡¨ 4/9: æ··æ·†çŸ©é™£æ¯”è¼ƒ")
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))
        
        model_names = ['Decision Tree', 'Logistic Regression']
        for i, (model_name, results) in enumerate(self.results.items()):
            cm = confusion_matrix(self.y_test, results['y_test_pred'])
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],
                       xticklabels=['No Disease', 'Disease'],
                       yticklabels=['No Disease', 'Disease'])
            axes[i].set_title(f'{model_names[i]} Confusion Matrix')
            axes[i].set_xlabel('Predicted')
            axes[i].set_ylabel('Actual')
        
        plt.tight_layout()
        plt.savefig(f'{save_path}04_confusion_matrices.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 5. ROCæ›²ç·šæ¯”è¼ƒ
        print("ğŸ“Š ç”Ÿæˆåœ–è¡¨ 5/9: ROCæ›²ç·šæ¯”è¼ƒ")
        plt.figure(figsize=(8, 6))
        
        for model_name, results in self.results.items():
            fpr, tpr, _ = roc_curve(self.y_test, results['y_test_proba'])
            auc_score = results['roc_auc']
            plt.plot(fpr, tpr, label=f"{model_name.replace('_', ' ').title()} (AUC = {auc_score:.3f})")
        
        plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curves Comparison')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'{save_path}05_roc_curves.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 6. ç‰¹å¾µé‡è¦æ€§æ¯”è¼ƒ
        print("ğŸ“Š ç”Ÿæˆåœ–è¡¨ 6/9: ç‰¹å¾µé‡è¦æ€§æ¯”è¼ƒ")
        fig, axes = plt.subplots(1, 2, figsize=(16, 8))
        
        for i, (model_name, results) in enumerate(self.results.items()):
            top_features = results['feature_importance'].head(10)
            bars = axes[i].barh(range(len(top_features)), top_features['importance'])
            axes[i].set_yticks(range(len(top_features)))
            axes[i].set_yticklabels(top_features['feature'])
            axes[i].set_xlabel('Importance Score')
            axes[i].set_title(f'{model_name.replace("_", " ").title()} - Top 10 Important Features')
            axes[i].invert_yaxis()
            
            # æ·»åŠ æ•¸å€¼æ¨™ç±¤
            for j, (bar, value) in enumerate(zip(bars, top_features['importance'])):
                axes[i].text(bar.get_width() + max(top_features['importance'])*0.01, 
                           bar.get_y() + bar.get_height()/2, 
                           f'{value:.3f}', va='center')
        
        plt.tight_layout()
        plt.savefig(f'{save_path}06_feature_importance.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 7. æ±ºç­–æ¨¹çµæ§‹åœ–
        print("ğŸ“Š ç”Ÿæˆåœ–è¡¨ 7/9: æ±ºç­–æ¨¹çµæ§‹")
        plt.figure(figsize=(20, 12))
        plot_tree(self.models['decision_tree'], 
                 feature_names=self.X.columns,
                 class_names=['No Disease', 'Disease'],
                 filled=True, rounded=True, fontsize=10)
        plt.title('Decision Tree Structure', fontsize=16)
        plt.tight_layout()
        plt.savefig(f'{save_path}07_decision_tree.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 8. Precision-Recallæ›²ç·š
        print("ğŸ“Š ç”Ÿæˆåœ–è¡¨ 8/9: Precision-Recallæ›²ç·š")
        plt.figure(figsize=(8, 6))
        
        for model_name, results in self.results.items():
            precision, recall, _ = precision_recall_curve(self.y_test, results['y_test_proba'])
            plt.plot(recall, precision, label=f"{model_name.replace('_', ' ').title()}")
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curves')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'{save_path}08_precision_recall.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 9. æ¨¡å‹æ€§èƒ½æ¯”è¼ƒé›·é”åœ–
        print("ğŸ“Š ç”Ÿæˆåœ–è¡¨ 9/9: æ¨¡å‹æ€§èƒ½æ¯”è¼ƒ")
        fig, ax = plt.subplots(figsize=(10, 8))
        
        # æº–å‚™è³‡æ–™
        metrics = ['Test Accuracy', 'Precision', 'Recall', 'F1 Score']
        metric_keys = ['test_accuracy', 'precision', 'recall', 'f1']
        dt_scores = [self.results['decision_tree'][key] for key in metric_keys]
        lr_scores = [self.results['logistic_regression'][key] for key in metric_keys]
        
        x = np.arange(len(metrics))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, dt_scores, width, label='Decision Tree', alpha=0.8)
        bars2 = ax.bar(x + width/2, lr_scores, width, label='Logistic Regression', alpha=0.8)
        
        ax.set_xlabel('Metrics')
        ax.set_ylabel('Score')
        ax.set_title('Model Performance Comparison')
        ax.set_xticks(x)
        ax.set_xticklabels(metrics)
        ax.legend()
        ax.set_ylim(0, 1.1)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                       f'{height:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig(f'{save_path}09_performance_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ… æ‰€æœ‰è¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆå®Œæˆ!")
        print(f"   åœ–è¡¨ä¿å­˜è·¯å¾‘: {save_path}")
        
    def generate_detailed_report(self, save_path='/mnt/user-data/outputs/'):
        """ç”Ÿæˆè©³ç´°åˆ†æå ±å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“„ æ­¥é©Ÿ6: ç”Ÿæˆè©³ç´°åˆ†æå ±å‘Š")
        print("="*60)
        
        report = []
        report.append("# è…è‡Ÿç–¾ç—…é æ¸¬æ¨¡å‹ - è©³ç´°åˆ†æå ±å‘Š")
        report.append("=" * 60)
        report.append("")
        
        # 1. å°ˆæ¡ˆæ¦‚è¿°
        report.append("## ğŸ“‹ å°ˆæ¡ˆæ¦‚è¿°")
        report.append("")
        report.append("æœ¬å°ˆæ¡ˆæ—¨åœ¨å»ºç«‹æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ä¾†é æ¸¬æ…¢æ€§è…è‡Ÿç–¾ç—…ï¼Œä½¿ç”¨æ±ºç­–æ¨¹å’Œé‚è¼¯å›æ­¸")
        report.append("å…©ç¨®æ¼”ç®—æ³•é€²è¡Œæ¯”è¼ƒåˆ†æã€‚")
        report.append("")
        report.append("**ä¸»è¦ç›®æ¨™ï¼š**")
        report.append("- å»ºç«‹æº–ç¢ºçš„è…è‡Ÿç–¾ç—…é æ¸¬æ¨¡å‹")
        report.append("- æ¯”è¼ƒä¸åŒæ©Ÿå™¨å­¸ç¿’æ¼”ç®—æ³•çš„æ€§èƒ½")
        report.append("- è­˜åˆ¥æœ€é‡è¦çš„é æ¸¬ç‰¹å¾µ")
        report.append("- æä¾›å¯è§£é‡‹çš„é†«å­¸é æ¸¬å·¥å…·")
        report.append("")
        
        # 2. è³‡æ–™é›†è³‡è¨Š
        report.append("## ğŸ“Š è³‡æ–™é›†è³‡è¨Š")
        report.append("")
        report.append(f"**è³‡æ–™å½¢ç‹€ï¼š** {self.data.shape}")
        report.append(f"**ç‰¹å¾µæ•¸é‡ï¼š** {self.X.shape[1]}")
        report.append(f"**æ¨£æœ¬æ•¸é‡ï¼š** {len(self.data)}")
        report.append("")
        
        # ç›®æ¨™è®Šæ•¸åˆ†å¸ƒ
        target_counts = pd.Series(self.y).value_counts().sort_index()
        report.append("**ç›®æ¨™è®Šæ•¸åˆ†å¸ƒï¼š**")
        for i, count in enumerate(target_counts.values):
            class_name = "ç„¡è…ç—…" if i == 0 else "æœ‰è…ç—…"
            percentage = (count / len(self.y)) * 100
            report.append(f"- {class_name}: {count} ({percentage:.1f}%)")
        report.append("")
        
        # 3. è³‡æ–™é è™•ç†
        report.append("## ğŸ”§ è³‡æ–™é è™•ç†")
        report.append("")
        report.append("**é—œéµæ­¥é©Ÿï¼š**")
        report.append("1. **ç§»é™¤è³‡æ–™æ´©æ¼ç‰¹å¾µ**ï¼š")
        for feature in self.leakage_features:
            report.append(f"   - {feature} (è…ç—…çš„ç—‡ç‹€ï¼Œéé æ¸¬å› å­)")
        report.append("")
        report.append("2. **ç‰¹å¾µç·¨ç¢¼**ï¼šå°‡åˆ†é¡è®Šæ•¸è½‰æ›ç‚ºæ•¸å€¼")
        report.append("3. **è³‡æ–™åˆ†å‰²**ï¼š80%è¨“ç·´é›†ï¼Œ20%æ¸¬è©¦é›†")
        report.append("4. **æ¨™æº–åŒ–**ï¼šé‚è¼¯å›æ­¸ä½¿ç”¨ç‰¹å¾µæ¨™æº–åŒ–")
        report.append("")
        
        # 4. æ¨¡å‹æ€§èƒ½
        report.append("## ğŸ¯ æ¨¡å‹æ€§èƒ½")
        report.append("")
        
        # æ€§èƒ½æ¯”è¼ƒè¡¨
        report.append("### è©³ç´°æ€§èƒ½æŒ‡æ¨™")
        report.append("")
        report.append("| æ¨¡å‹ | äº¤å‰é©—è­‰æº–ç¢ºç‡ | æ¸¬è©¦é›†æº–ç¢ºç‡ | ç²¾ç¢ºç‡ | å¬å›ç‡ | F1åˆ†æ•¸ | ROC AUC |")
        report.append("|------|---------------|-------------|--------|-------|--------|---------|")
        
        for model_name, results in self.results.items():
            model_display = model_name.replace('_', ' ').title()
            report.append(f"| {model_display} | {results['cv_accuracy']:.4f}Â±{results['cv_std']:.4f} | "
                         f"{results['test_accuracy']:.4f} | {results['precision']:.4f} | "
                         f"{results['recall']:.4f} | {results['f1']:.4f} | {results['roc_auc']:.4f} |")
        
        report.append("")
        
        # 5. ç‰¹å¾µé‡è¦æ€§åˆ†æ
        report.append("## ğŸ“ˆ ç‰¹å¾µé‡è¦æ€§åˆ†æ")
        report.append("")
        
        for model_name, results in self.results.items():
            model_display = model_name.replace('_', ' ').title()
            report.append(f"### {model_display} å‰10é‡è¦ç‰¹å¾µ")
            report.append("")
            report.append("| æ’å | ç‰¹å¾µåç¨± | é‡è¦æ€§åˆ†æ•¸ |")
            report.append("|------|----------|-----------|")
            
            top_features = results['feature_importance'].head(10)
            for i, (_, row) in enumerate(top_features.iterrows(), 1):
                report.append(f"| {i} | {row['feature']} | {row['importance']:.4f} |")
            
            report.append("")
        
        # 6. é—œéµç™¼ç¾
        report.append("## ğŸ” é—œéµç™¼ç¾")
        report.append("")
        
        # æ‰¾å‡ºæœ€é‡è¦çš„ç‰¹å¾µ
        dt_top_feature = self.results['decision_tree']['feature_importance'].iloc[0]
        lr_top_feature = self.results['logistic_regression']['feature_importance'].iloc[0]
        
        report.append("**æœ€é‡è¦çš„é æ¸¬å› å­ï¼š**")
        report.append(f"- æ±ºç­–æ¨¹: {dt_top_feature['feature']} (é‡è¦æ€§: {dt_top_feature['importance']:.4f})")
        report.append(f"- é‚è¼¯å›æ­¸: {lr_top_feature['feature']} (é‡è¦æ€§: {lr_top_feature['importance']:.4f})")
        report.append("")
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model_name = max(self.results.keys(), 
                             key=lambda x: self.results[x]['test_accuracy'])
        best_accuracy = self.results[best_model_name]['test_accuracy']
        
        report.append("**æœ€ä½³æ¨¡å‹ï¼š**")
        report.append(f"- {best_model_name.replace('_', ' ').title()}")
        report.append(f"- æ¸¬è©¦é›†æº–ç¢ºç‡: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)")
        report.append("")
        
        # 7. é†«å­¸æ„ç¾©
        report.append("## ğŸ¥ é†«å­¸æ„ç¾©")
        report.append("")
        report.append("**æ¨¡å‹çš„è‡¨åºŠåƒ¹å€¼ï¼š**")
        report.append("- **æ—©æœŸç¯©æª¢**ï¼šèƒ½åœ¨ç—‡ç‹€å‡ºç¾å‰è­˜åˆ¥é«˜é¢¨éšªæ‚£è€…")
        report.append("- **å®¢è§€è¨ºæ–·**ï¼šåŸºæ–¼é‡åŒ–æŒ‡æ¨™ï¼Œæ¸›å°‘ä¸»è§€åˆ¤æ–·èª¤å·®")
        report.append("- **è³‡æºé…ç½®**ï¼šå¹«åŠ©é†«ç™‚æ©Ÿæ§‹å„ªåŒ–è³‡æºåˆ†é…")
        report.append("- **å€‹äººåŒ–é†«ç™‚**ï¼šç‚ºä¸åŒé¢¨éšªç­‰ç´šæ‚£è€…æä¾›é©ç•¶çš„ç…§è­·è¨ˆç•«")
        report.append("")
        
        # 8. æ¨¡å‹é™åˆ¶
        report.append("## âš ï¸ æ¨¡å‹é™åˆ¶èˆ‡æ³¨æ„äº‹é …")
        report.append("")
        report.append("**ä½¿ç”¨é™åˆ¶ï¼š**")
        report.append("- æ¨¡å‹åŸºæ–¼ç‰¹å®šè³‡æ–™é›†è¨“ç·´ï¼Œå¯èƒ½ä¸é©ç”¨æ–¼æ‰€æœ‰äººç¾¤")
        report.append("- éœ€è¦å®šæœŸé©—è­‰å’Œæ›´æ–°æ¨¡å‹æ€§èƒ½")
        report.append("- æ‡‰ä½œç‚ºè¼”åŠ©è¨ºæ–·å·¥å…·ï¼Œä¸èƒ½æ›¿ä»£å°ˆæ¥­é†«å­¸åˆ¤æ–·")
        report.append("- å»ºè­°çµåˆè‡¨åºŠç¶“é©—å’Œå…¶ä»–è¨ºæ–·æ–¹æ³•ä½¿ç”¨")
        report.append("")
        
        # 9. çµè«–
        report.append("## ğŸ“‹ çµè«–")
        report.append("")
        report.append("æœ¬ç ”ç©¶æˆåŠŸå»ºç«‹äº†é«˜æº–ç¢ºç‡çš„è…è‡Ÿç–¾ç—…é æ¸¬æ¨¡å‹ï¼š")
        report.append("")
        best_results = self.results[best_model_name]
        report.append(f"- **æœ€ä½³æ¨¡å‹æº–ç¢ºç‡**: {best_results['test_accuracy']:.1%}")
        report.append(f"- **ç²¾ç¢ºç‡**: {best_results['precision']:.1%} (ä½å‡é™½æ€§ç‡)")
        report.append(f"- **å¬å›ç‡**: {best_results['recall']:.1%} (ä½å‡é™°æ€§ç‡)")
        report.append(f"- **ROC AUC**: {best_results['roc_auc']:.3f} (å„ªç§€çš„åˆ¤åˆ¥èƒ½åŠ›)")
        report.append("")
        report.append("æ¨¡å‹å±•ç¾äº†è‰¯å¥½çš„é æ¸¬æ€§èƒ½å’Œè‡¨åºŠæ‡‰ç”¨æ½œåŠ›ï¼Œ")
        report.append("å¯ä»¥ä½œç‚ºé†«ç™‚æ±ºç­–æ”¯æŒç³»çµ±çš„é‡è¦çµ„æˆéƒ¨åˆ†ã€‚")
        
        # ä¿å­˜å ±å‘Š
        report_text = "\n".join(report)
        with open(f'{save_path}kidney_disease_analysis_report.md', 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print("âœ… è©³ç´°åˆ†æå ±å‘Šç”Ÿæˆå®Œæˆ!")
        print(f"   å ±å‘Šä¿å­˜æ–¼: {save_path}kidney_disease_analysis_report.md")
        
        return report_text
    
    def run_complete_analysis(self):
        """åŸ·è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸš€ é–‹å§‹è…è‡Ÿç–¾ç—…é æ¸¬æ¨¡å‹å®Œæ•´åˆ†æ")
        print("=" * 80)
        
        try:
            # æ­¥é©Ÿ1: è¼‰å…¥å’Œæ¢ç´¢è³‡æ–™
            self.load_and_explore_data()
            
            # æ­¥é©Ÿ2: é è™•ç†è³‡æ–™
            self.preprocess_data()
            
            # æ­¥é©Ÿ3: åˆ†å‰²è³‡æ–™
            self.split_data()
            
            # æ­¥é©Ÿ4: è¨“ç·´æ¨¡å‹
            self.train_decision_tree()
            self.train_logistic_regression()
            
            # æ­¥é©Ÿ5: æ¯”è¼ƒæ¨¡å‹
            self.compare_models()
            
            # æ­¥é©Ÿ6: å‰µå»ºè¦–è¦ºåŒ–
            self.create_visualizations()
            
            # æ­¥é©Ÿ7: ç”Ÿæˆå ±å‘Š
            self.generate_detailed_report()
            
            print("\n" + "ğŸ‰" * 20)
            print("ğŸ‰ è…è‡Ÿç–¾ç—…é æ¸¬åˆ†æå®Œæˆ!")
            print("ğŸ‰" * 20)
            print("\nğŸ“ ç”Ÿæˆçš„æª”æ¡ˆ:")
            print("   ğŸ“Š 9å¼µåˆ†æåœ–è¡¨ (01_*.png - 09_*.png)")
            print("   ğŸ“„ è©³ç´°åˆ†æå ±å‘Š (kidney_disease_analysis_report.md)")
            print("   ğŸ’¾ è¨“ç·´å¥½çš„æ¨¡å‹ç‰©ä»¶")
            
            # é¡¯ç¤ºæœ€ä½³çµæœ
            best_model_name = max(self.results.keys(), 
                                 key=lambda x: self.results[x]['test_accuracy'])
            best_results = self.results[best_model_name]
            
            print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model_name.replace('_', ' ').title()}")
            print(f"   ğŸ“Š æ¸¬è©¦é›†æº–ç¢ºç‡: {best_results['test_accuracy']:.1%}")
            print(f"   ğŸ¯ ç²¾ç¢ºç‡: {best_results['precision']:.1%}")
            print(f"   ğŸ” å¬å›ç‡: {best_results['recall']:.1%}")
            print(f"   â­ F1åˆ†æ•¸: {best_results['f1']:.1%}")
            print(f"   ğŸ“ˆ ROC AUC: {best_results['roc_auc']:.3f}")
            
            return True
            
        except Exception as e:
            print(f"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # å‰µå»ºé æ¸¬å™¨
    predictor = KidneyDiseasePredictor('/mnt/user-data/uploads/kidney_disease.csv')
    
    # åŸ·è¡Œå®Œæ•´åˆ†æ
    success = predictor.run_complete_analysis()
    
    if success:
        print("\nâœ… åˆ†ææˆåŠŸå®Œæˆ!")
        print("\nğŸ’¡ ä½¿ç”¨èªªæ˜:")
        print("1. æŸ¥çœ‹ç”Ÿæˆçš„9å¼µåœ–è¡¨äº†è§£è³‡æ–™å’Œæ¨¡å‹æ€§èƒ½")
        print("2. é–±è®€è©³ç´°å ±å‘Šäº†è§£å®Œæ•´åˆ†æçµæœ")
        print("3. æ¨¡å‹ç‰©ä»¶å·²ä¿å­˜ï¼Œå¯ç”¨æ–¼æ–°è³‡æ–™é æ¸¬")
        print("4. æ‰€æœ‰æª”æ¡ˆä½æ–¼ /mnt/user-data/outputs/ ç›®éŒ„")
    else:
        print("\nâŒ åˆ†æå¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤ä¿¡æ¯ä¸¦é‡è©¦")
